{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31aa696c",
   "metadata": {},
   "source": [
    "# Selección de Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab0fd8",
   "metadata": {},
   "source": [
    "A continuación, se mostrará el proceso de selección del modelo, las posibles mejoras y conclusiones de la elección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d071ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f8bdb",
   "metadata": {},
   "source": [
    "## 0.- Carga de Conjuntos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff2f325",
   "metadata": {},
   "source": [
    "Se cargan los .csv correspondientes al conjunto de entrenamiento y prueba. Ambos .csv contienen las carácteristicas obtenidas del notebook original. En los .csv, la primera columna corresponde a la clase de la fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3fc827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('datasets/x_train.csv', header = None).to_numpy()\n",
    "y_train = np.ravel(pd.read_csv('datasets/y_train.csv', header = None).to_numpy())\n",
    "x_test = pd.read_csv('datasets/x_test.csv', header = None).to_numpy()\n",
    "y_test = np.ravel(pd.read_csv('datasets/y_test.csv', header = None).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a06c98f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45698, 37) (22508, 37)\n",
      "(45698,) (22508,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93108d2a",
   "metadata": {},
   "source": [
    "Tambien se cargan los .csv correspondientes a los conjuntos seleccionando las características más importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fe4eb5",
   "metadata": {},
   "source": [
    "## 1.- Primera Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c5eaff",
   "metadata": {},
   "source": [
    "### 1.1.- Logistic Regression Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a97d51c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression()\n",
    "model = logReg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdb73463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en predicción: 0.0072650909423828125 [s]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = model.predict(x_test)\n",
    "end = time.time()\n",
    "print(\"Tiempo en predicción:\", end - start, \"[s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf96bb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18311,    92],\n",
       "       [ 3985,   120]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf0c5882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90     18403\n",
      "           1       0.57      0.03      0.06      4105\n",
      "\n",
      "    accuracy                           0.82     22508\n",
      "   macro avg       0.69      0.51      0.48     22508\n",
      "weighted avg       0.77      0.82      0.75     22508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8512a447",
   "metadata": {},
   "source": [
    "### 1.2.- XGBClassifier Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8021285",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelxgb = xgb.XGBClassifier(random_state=1, learning_rate=0.01, objective='binary:logistic')\n",
    "modelxgb = modelxgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92b39075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en predicción: 0.0253598690032959 [s]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_predxgb = modelxgb.predict(x_test)\n",
    "end = time.time()\n",
    "print(\"Tiempo en predicción:\", end - start, \"[s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55648879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18359,    44],\n",
       "       [ 4017,    88]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predxgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91852ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90     18403\n",
      "           1       0.67      0.02      0.04      4105\n",
      "\n",
      "    accuracy                           0.82     22508\n",
      "   macro avg       0.74      0.51      0.47     22508\n",
      "weighted avg       0.79      0.82      0.74     22508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predxgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843f5224",
   "metadata": {},
   "source": [
    "### 1.3.- Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eac9c14",
   "metadata": {},
   "source": [
    "Es posible apreciar que el modelo de Regresión Logística tiene mejor rendimiento en la clasificación que el modelo de XGBClassifier, ya que, obtiene una mejor clasificación en la clase '1' o 'Atraso' y casi el mismo rendimiento en la clase '0' o 'No Atraso'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffd041e",
   "metadata": {},
   "source": [
    "Además, se puede apreciar que en tiempos de procesamiento, el modelo de Regresión Logística tarda menos tiempo (0.004 [s] vs 0.03 [s]) en predecir la clase de un vuelo. Lo cual tiene relevancia a la hora de exponer el modelo y realizar multiples solicitudes en poco tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972a4b7",
   "metadata": {},
   "source": [
    "Tal como se mencionó en el notebook original, ambos rendimientos no son suficientes para resolver el problema deseado, ya que, la cantidad de falsos negativos es demasiada alta, debido al imbalance de las clases. Es por esto, que se decide evaluar el desempeño de ambos modelos aplicando un **peso** a las clases al momento de entrenar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f955c7",
   "metadata": {},
   "source": [
    "El modelo de Regresión Logística posee un parámetro llamado **class_weight**, que permite equiparar el peso entre las clases para mejorar el imbalance que hay en los conjuntos en el entrenamiento. Así también, existe el parámetro **scale_pos_weight** en el modelo de XGBClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f577c767",
   "metadata": {},
   "source": [
    "## 2.- Mejoras y  Segunda Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6f42e5",
   "metadata": {},
   "source": [
    "### 2.1.- Logistic Regression Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01e06eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression(class_weight = 'balanced')\n",
    "model = logReg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83a7938b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en predicción: 0.00750279426574707 [s]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_pred = model.predict(x_test)\n",
    "end = time.time()\n",
    "print(\"Tiempo en predicción:\", end - start, \"[s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c01e37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10958,  7445],\n",
       "       [ 1477,  2628]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f345d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.60      0.71     18403\n",
      "           1       0.26      0.64      0.37      4105\n",
      "\n",
      "    accuracy                           0.60     22508\n",
      "   macro avg       0.57      0.62      0.54     22508\n",
      "weighted avg       0.77      0.60      0.65     22508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e69cf4a",
   "metadata": {},
   "source": [
    "### 2.2.- XGBClassifier Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c35b651",
   "metadata": {},
   "source": [
    "Se calcula la proporción de imbalance entre las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b0b7127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3705488306499\n"
     ]
    }
   ],
   "source": [
    "n_y0 = len(y_train[y_train == 0])\n",
    "n_y1 = len(y_train[y_train == 1])\n",
    "scale = n_y0/n_y1\n",
    "print(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d20736b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:27:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "modelxgb = xgb.XGBClassifier(random_state=1, learning_rate=0.01, objective='binary:logistic', scale_pos_weight = scale)\n",
    "modelxgb = modelxgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6dfc2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo en predicción: 0.06588602066040039 [s]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_predxgb = modelxgb.predict(x_test)\n",
    "end = time.time()\n",
    "print(\"Tiempo en predicción:\", end - start, \"[s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0d42921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9591, 8812],\n",
       "       [1238, 2867]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predxgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cbbecf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.52      0.66     18403\n",
      "           1       0.25      0.70      0.36      4105\n",
      "\n",
      "    accuracy                           0.55     22508\n",
      "   macro avg       0.57      0.61      0.51     22508\n",
      "weighted avg       0.77      0.55      0.60     22508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predxgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5749ee",
   "metadata": {},
   "source": [
    "### 2.3.- Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76e7f4c",
   "metadata": {},
   "source": [
    "Con los cambios realizados en ambos modelos, es posible apreciar que el rendimiento ha cambiado considerablemente. Teniendo ambos modelos un comportamiento similar, si bien la clasificación de la clase '0' o 'No Atraso' disminuyó su rendimiento (esperable por el balanceo de clases), la clasificación de la clase '1' o 'Atraso' aumento considerablemente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81bb0b2",
   "metadata": {},
   "source": [
    "En consecuencia, la cantidad de falsos negativos disminuyeron considerablemente, y por el contrario, los falsos positivos aumentaron. Pero, **¿Se puede determinar esta situación como mejor?**. Para la resolución del problema de negocio, se entenderá como positivo el aumento de falsos positivos (y por consecuencia la disminución de falsos negativos), ya que, es preferible determinar que un avión llegará atrasado y que este **no** llegue atrasado, que, determinar que un avión no llegará atrasado y si lo haga. De esta manera, se pueden tener consideraciones a la hora de que un vuelo llegue o salga del aeropuerto con un mejor resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0018c297",
   "metadata": {},
   "source": [
    "Finalmente, se considera que el mejor modelo (y el seleccionado) es el de **Regresión Logística**, el cual tiene un mejor rendimiento que el de XGBoost, y, con un tiempo de procesamiento mucho menor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sre",
   "language": "python",
   "name": "sre"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
